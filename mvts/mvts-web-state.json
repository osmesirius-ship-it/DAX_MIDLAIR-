{
  "beliefs": {
    "coherence": 0.83304965354852,
    "reliability": 0.9,
    "learning_rate": 0.08100000000000002,
    "confidence": 0.7900701281834623,
    "last_updated": "2025-12-22T15:29:45.817288"
  },
  "memory": [
    {
      "type": "cognitive_loop",
      "loop_id": "loop_4d21f988",
      "goal": "fund an account with money",
      "success": true,
      "learning": [
        "Updated confidence to 0.748",
        "Decreased learning rate due to high success",
        "Updated coherence to 0.818"
      ],
      "timestamp": "2025-12-22T15:28:57.498747"
    },
    {
      "type": "cognitive_loop",
      "loop_id": "loop_55ebc447",
      "goal": "Good. What you wrote is *structurally right*. Now we make it **buildable**.\n\nBelow is an **EDI v1 spec** (inputs \u2192 core computations \u2192 outputs) plus an **executable Python reference implementation** that plugs into your Phase-10/Phase-Lock simulation style: EDI generates **salience S(t)**, **coherence C(t)**, **anomaly phase signature \u03a6(t)**, then biases a DAX-like planner (control knob updates / constraint penalties).\n\n---\n\n## EDI v1: minimal, rigorous spec\n\n### Inputs (all time series, sampled at `fs` Hz)\n\n* `x_k[t]` sensor streams (thermal, vibration, EM, power, nav residuals, etc.), standardized.\n* `r_k[t]` model residuals (predicted \u2212 observed) for each sensor/subsystem.\n* optional: `u[t]` control history (knob positions / action vectors).\n\n### Core computations (what EDI actually *does*)\n\n1. **Phase drift** (relative timing/phase between key pairs of signals)\n2. **Cross-correlation spike** (weak coupling turning on)\n3. **Spectral entropy / \u201cgetting noisier in a specific way\u201d**\n4. **Residual surprise** (z-scored innovation: sudden mismatch between model and reality)\n5. **Coherence estimator** (how stable/organized the system is right now)\n\n### Outputs (what EDI exports)\n\n* **Salience map** `S_k(t) \u2208 [0,1]` : \u201cwatch this now/soon\u201d\n* **Coherence scalar** `C(t) \u2208 [0,1]` : \u201cstay in stable basins\u201d\n* **Anomaly phase signature** `\u03a6(t)` : compact vector of anomaly features (phase drift, corr spikes, entropy delta, residual spikes)\n\n### How it \u201cpilots\u201d DAX (no hand-waving)\n\nDAX planner solves an objective like:\n\n[\n\\min_{u_t} ;; J_\\text{mission}(u_t) ;+; \\lambda \\cdot (1 - C(t)) \\cdot J_\\text{risk}(u_t) ;+; \\sum_k S_k(t)\\cdot J_k(u_t)\n]\n\nTranslation: when coherence drops, EDI increases penalties for risky actions; when a subsystem becomes salient, DAX pays more attention to constraints linked to that subsystem.\n\n---\n\n## Executable EDI v1 + demo simulation (copy/paste)\n\nThis runs standalone in Python/Jupyter. It includes:\n\n* streaming sensor synthesis (3 scenarios: solar-storm, micrometeoroid, spoof)\n* EDI computations (phase drift, corr spikes, spectral entropy, residual surprise)\n* DAX-style \u201cknob\u201d update using EDI coherence/salience (soft constraints)\n* plots + metrics\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# -----------------------------\n# Utilities\n# -----------------------------\ndef zscore(x, eps=1e-9):\n    x = np.asarray(x)\n    return (x - x.mean()) / (x.std() + eps)\n\ndef moving_mean(x, w):\n    x = np.asarray(x)\n    if w <= 1:\n        return x.copy()\n    k = np.ones(w) / w\n    return np.convolve(x, k, mode=\"same\")\n\ndef spectral_entropy(x, fs, nfft=256, eps=1e-12):\n    \"\"\"\n    Shannon entropy of normalized power spectrum in [0,1].\n    Higher = flatter/noisier. Lower = structured/tonal.\n    \"\"\"\n    x = np.asarray(x)\n    if len(x) < nfft:\n        # pad\n        pad = np.zeros(nfft - len(x))\n        x = np.concatenate([x, pad])\n    X = np.fft.rfft(x[:nfft] * np.hanning(nfft))\n    P = (np.abs(X) ** 2)\n    P = P / (P.sum() + eps)\n    H = -(P * np.log(P + eps)).sum()\n    H_norm = H / np.log(len(P) + eps)\n    return float(np.clip(H_norm, 0.0, 1.0))\n\ndef phase_drift_metric(x, y, fs, nfft=256, eps=1e-12):\n    \"\"\"\n    Lightweight phase drift proxy:\n    compute cross-spectrum phase at dominant frequency of x.\n    Return absolute phase difference in [0, pi].\n    \"\"\"\n    x = np.asarray(x); y = np.asarray(y)\n    if len(x) < nfft:\n        x = np.pad(x, (0, nfft-len(x)))\n        y = np.pad(y, (0, nfft-len(y)))\n    wx = x[:nfft] * np.hanning(nfft)\n    wy = y[:nfft] * np.hanning(nfft)\n    X = np.fft.rfft(wx)\n    Y = np.fft.rfft(wy)\n    Pxx = np.abs(X)**2\n    k = int(np.argmax(Pxx[1:]) + 1)  # ignore DC\n    cross = X[k] * np.conj(Y[k])\n    phase = np.angle(cross)\n    return float(np.abs(((phase + np.pi) % (2*np.pi)) - np.pi))  # wrap to [-pi,pi], abs\n\ndef xcorr_peak(x, y, max_lag=50):\n    \"\"\"\n    Normalized cross-correlation peak magnitude in [0,1].\n    \"\"\"\n    x = zscore(x); y = zscore(y)\n    n = len(x)\n    lags = range(-max_lag, max_lag+1)\n    peaks = []\n    for lag in lags:\n        if lag < 0:\n            a = x[:lag]\n            b = y[-lag:]\n        elif lag > 0:\n            a = x[lag:]\n            b = y[:-lag]\n        else:\n            a = x\n            b = y\n        if len(a) < 10:\n            continue\n        peaks.append(np.abs(np.corrcoef(a, b)[0,1]))\n    return float(np.clip(np.max(peaks) if peaks else 0.0, 0.0, 1.0))\n\n# -----------------------------\n# EDI v1\n# -----------------------------\nclass EDIv1:\n    \"\"\"\n    Extended Detection & Integration (v1)\n    Computes:\n      - salience S_k(t) for each channel\n      - coherence C(t)\n      - anomaly phase signature Phi(t) (feature vector)\n    \"\"\"\n    def __init__(self, fs, window_s=2.0):\n        self.fs = fs\n        self.w = max(32, int(window_s * fs))  # analysis window\n        self.eps = 1e-9\n\n    def step(self, X, R, key_pairs=None):\n        \"\"\"\n        X: (T, K) sensor streams\n        R: (T, K) residual streams\n        key_pairs: list of (i,j) indices for phase/correlation tracking\n        returns: S (K,), C scalar, Phi dict\n        \"\"\"\n        T, K = X.shape\n        w = min(self.w, T)\n        xw = X[-w:, :]\n        rw = R[-w:, :]\n\n        # Per-channel features\n        ent = np.array([spectral_entropy(xw[:,k], fs=self.fs) for k in range(K)])\n        res = np.array([np.mean(np.abs(zscore(rw[:,k]))) for k in range(K)])  # residual surprise proxy\n\n        # Pairwise features (phase drift + correlation spikes)\n        if key_pairs is None:\n            key_pairs = [(0,1)]\n        ph = []\n        cc = []\n        for (i,j) in key_pairs:\n            ph.append(phase_drift_metric(xw[:,i], xw[:,j], fs=self.fs))\n            cc.append(xcorr_peak(xw[:,i], xw[:,j], max_lag=int(0.2*self.fs)))\n        ph = np.array(ph)  # radians in [0,pi]\n        cc = np.array(cc)  # [0,1]\n\n        # Normalize phase drift into [0,1] (0 good, 1 bad)\n        ph_norm = np.clip(ph / np.pi, 0.0, 1.0)\n\n        # Salience: weighted combo of \"noisier\" + \"residual surprise\"\n        # (You can tune weights per subsystem)\n        S_raw = 0.55*ent + 0.45*np.clip(res / (np.max(res)+self.eps), 0, 1)\n        S = np.clip(S_raw, 0.0, 1.0)\n\n        # Coherence: high when entropy low, residual low, phase drift low, correlation stable\n        # We treat corr spikes as \"something coupling\" -> can be good or bad;\n        # Here we penalize sudden/high corr as risk unless known-safe.\n        C = 1.0 - np.clip(\n            0.35*np.mean(ent) +\n            0.35*np.clip(np.mean(res)/(np.max(res)+self.eps), 0, 1) +\n            0.20*np.mean(ph_norm) +\n            0.10*np.mean(cc),\n            0.0, 1.0\n        )\n\n        Phi = {\n            \"entropy_mean\": float(np.mean(ent)),\n            \"residual_mean\": float(np.mean(res)),\n            \"phase_drift_mean\": float(np.mean(ph_norm)),\n            \"xcorr_peak_mean\": float(np.mean(cc)),\n            \"phase_drift_pairs\": ph_norm.tolist(),\n            \"xcorr_pairs\": cc.tolist(),\n        }\n        return S, float(np.clip(C, 0.0, 1.0)), Phi\n\n# -----------------------------\n# Phase 10+EDI demo simulation\n# -----------------------------\ndef simulate_scenario(fs, T_s, scenario=\"solar_storm\", K=4, seed=7):\n    \"\"\"\n    Returns X(t,K), R(t,K)\n    Channels (example):\n      0 thermal, 1 vibration, 2 EM, 3 power residual proxy\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    T = int(T_s * fs)\n    t = np.arange(T) / fs\n\n    # Baselines\n    thermal = 0.2*np.sin(2*np.pi*0.08*t) + 0.05*rng.normal(size=T)\n    vib     = 0.15*np.sin(2*np.pi*0.6*t) + 0.07*rng.normal(size=T)\n    em      = 0.10*np.sin(2*np.pi*0.15*t) + 0.05*rng.normal(size=T)\n    power   = 0.05*np.sin(2*np.pi*0.03*t) + 0.03*rng.normal(size=T)\n\n    # Residuals: predicted-observed mismatch proxy\n    r_thermal = 0.03*rng.normal(size=T)\n    r_vib     = 0.03*rng.normal(size=T)\n    r_em      = 0.03*rng.normal(size=T)\n    r_power   = 0.03*rng.normal(size=T)\n\n    # Inject scenario dynamics\n    if scenario == \"solar_storm\":\n        # EM noise rises + power residual increases + phase relations drift\n        storm = (t > 0.4*T_s) & (t < 0.75*T_s)\n        em[storm] += 0.25*rng.normal(size=storm.sum())\n        power[storm] += 0.10*np.sin(2*np.pi*0.2*t[storm])\n        r_em[storm] += 0.12*rng.normal(size=storm.sum())\n        r_power[storm] += 0.10*rng.normal(size=storm.sum())\n\n    elif scenario == \"micrometeoroid\":\n        # sharp vibration impulse + thermal bump + short residual spike\n        hit_t = int(0.55*T)\n        width = int(0.05*T)\n        impulse = np.exp(-((np.arange(T)-hit_t)**2)/(2*(width**2)))\n        vib += 0.9*impulse\n        thermal += 0.35*impulse\n        r_vib += 0.25*impulse\n        r_thermal += 0.18*impulse\n\n    elif scenario == \"sensor_spoof\":\n        # correlated fake EM & power signals + residual mismatch pattern\n        spoof = (t > 0.35*T_s) & (t < 0.65*T_s)\n        fake = 0.35*np.sin(2*np.pi*0.9*t[spoof])\n        em[spoof] += fake\n        power[spoof] += 0.8*fake\n        # residuals show \"model doesn't believe it\"\n        r_em[spoof] += 0.20*rng.normal(size=spoof.sum())\n        r_power[spoof] += 0.20*rng.normal(size=spoof.sum())\n\n    X = np.stack([thermal, vib, em, power], axis=1)\n    R = np.stack([r_thermal, r_vib, r_em, r_power], axis=1)\n    return t, X, R\n\ndef dax_planner_step(knobs, S, C, Phi, lr=0.08):\n    \"\"\"\n    DAX-style \"soft constraint\" update:\n      - when coherence drops -> damp aggressive knobs\n      - when a channel becomes salient -> shift attention (example: reduce interference, raise smoothing)\n    knobs: dict {focus, entanglement, interference}\n    \"\"\"\n    focus = knobs[\"focus\"]\n    ent   = knobs[\"entanglement\"]\n    interf= knobs[\"interference\"]\n\n    # Coherence pressure: low C => reduce entanglement & interference, slightly increase focus stability\n    pressure = (1.0 - C)\n\n    ent   = np.clip(ent   * (1.0 - 0.6*pressure), 0.0, 1.0)\n    interf= np.clip(interf* (1.0 - 0.8*pressure), 0.0, 1.0)\n    focus = np.clip(focus + lr*(0.15*C - 0.10*pressure), 0.0, 1.0)\n\n    # Salience rules (example policy):\n    # if EM (channel 2) salient -> reduce interference more (treat as noise risk)\n    if S[2] > 0.7:\n        interf = np.clip(interf * (1.0 - 0.25*S[2]), 0.0, 1.0)\n\n    # if vibration (channel 1) salient -> reduce entanglement (avoid coupled decisions)\n    if S[1] > 0.7:\n        ent = np.clip(ent * (1.0 - 0.25*S[1]), 0.0, 1.0)\n\n    knobs[\"focus\"] = float(focus)\n    knobs[\"entanglement\"] = float(ent)\n    knobs[\"interference\"] = float(interf)\n    return knobs\n\ndef run_edi_demo(scenario=\"solar_storm\"):\n    fs = 200\n    T_s = 20\n    t, X, R = simulate_scenario(fs, T_s, scenario=scenario)\n\n    edi = EDIv1(fs=fs, window_s=2.0)\n    key_pairs = [(2,3), (0,2)]  # (EM,power), (thermal,EM)\n\n    # DAX knobs over time\n    knobs = {\"focus\": 0.8, \"entanglement\": 0.5, \"interference\": 0.3}\n    focus_hist = []\n    ent_hist = []\n    int_hist = []\n    C_hist = []\n    S_hist = []\n    ph_hist = []\n\n    # Run streaming\n    for i in range(len(t)):\n        S, C, Phi = edi.step(X[:i+1,:], R[:i+1,:], key_pairs=key_pairs)\n        knobs = dax_planner_step(knobs, S, C, Phi)\n        focus_hist.append(knobs[\"focus\"])\n        ent_hist.append(knobs[\"entanglement\"])\n        int_hist.append(knobs[\"interference\"])\n        C_hist.append(C)\n        S_hist.append(S)\n        ph_hist.append(Phi[\"phase_drift_mean\"])\n\n    S_hist = np.array(S_hist)  # (T,K)\n\n    # Plots\n    fig = plt.figure(figsize=(14, 10))\n\n    ax1 = plt.subplot(4,1,1)\n    ax1.plot(t, X[:,0], label=\"thermal\")\n    ax1.plot(t, X[:,1], label=\"vibration\")\n    ax1.plot(t, X[:,2], label=\"EM\")\n    ax1.plot(t, X[:,3], label=\"power\")\n    ax1.set_title(f\"Sensors X(t) \u2014 scenario: {scenario}\")\n    ax1.legend(loc=\"upper right\")\n\n    ax2 = plt.subplot(4,1,2)\n    ax2.plot(t, C_hist, label=\"C(t) coherence\")\n    ax2.plot(t, ph_hist, label=\"mean phase drift (norm)\")\n    ax2.set_ylim(-0.05, 1.05)\n    ax2.set_title(\"EDI: Coherence + Phase Drift\")\n    ax2.legend(loc=\"upper right\")\n\n    ax3 = plt.subplot(4,1,3)\n    ax3.plot(t, S_hist[:,0], label=\"S_thermal\")\n    ax3.plot(t, S_hist[:,1], label=\"S_vibration\")\n    ax3.plot(t, S_hist[:,2], label=\"S_EM\")\n    ax3.plot(t, S_hist[:,3], label=\"S_power\")\n    ax3.set_ylim(-0.05, 1.05)\n    ax3.set_title(\"EDI: Salience map S_k(t)\")\n    ax3.legend(loc=\"upper right\")\n\n    ax4 = plt.subplot(4,1,4)\n    ax4.plot(t, focus_hist, label=\"focus\")\n    ax4.plot(t, ent_hist, label=\"entanglement\")\n    ax4.plot(t, int_hist, label=\"interference\")\n    ax4.set_ylim(-0.05, 1.05)\n    ax4.set_title(\"DAX knobs (pilot bias from EDI)\")\n    ax4.legend(loc=\"upper right\")\n\n    plt.tight_layout()\n    plt.show()\n\n    # Metrics summary\n    C_arr = np.array(C_hist)\n    summary = {\n        \"scenario\": scenario,\n        \"coherence_mean\": float(C_arr.mean()),\n        \"coherence_min\": float(C_arr.min()),\n        \"max_salience_EM\": float(S_hist[:,2].max()),\n        \"max_salience_vibration\": float(S_hist[:,1].max()),\n        \"final_knobs\": {\n            \"focus\": float(focus_hist[-1]),\n            \"entanglement\": float(ent_hist[-1]),\n            \"interference\": float(int_hist[-1]),\n        }\n    }\n    return summary\n\n# ---- Run one scenario now (change as needed)\nsummary = run_edi_demo(\"solar_storm\")\nprint(summary)\n```\n\n### What you should see\n\n* In **solar_storm**, EM salience spikes and coherence drops; DAX knobs \u201ctighten\u201d (lower interference/entanglement).\n* In **micrometeoroid**, vibration salience spikes sharply; coherence dips briefly then recovers.\n* In **sensor_spoof**, EM and power become overly correlated; EDI penalizes via coherence & salience, pushing DAX away from coupled/greedy actions.\n\nRun:\n\n```python\nrun_edi_demo(\"micrometeoroid\")\nrun_edi_demo(\"sensor_spoof\")\n```\n\n---\n\n## What to do next (so it\u2019s not just a demo)\n\nIf you want EDI to be \u201cpilot-grade\u201d:\n\n1. Replace the toy residuals with **real model residuals** (Kalman filter innovation, or learned predictor error).\n2. Make `key_pairs` explicit per subsystem (power\u2194thermal, EM\u2194comms, vibration\u2194attitude).\n3. Add **mode switching** (UCT layer): if `C(t)` stays < 0.35 for N seconds \u2192 \u201csurvival mode\u201d policy.\n\nIf you say \u201cexport this into the real repo zip,\u201d I\u2019ll generate a **non-placeholder export** with:\n\n* `backend/edi.py` (this class)\n* `backend/phase10_sim.py` updated to use EDI outputs\n* `/api/edi/stream` + `/api/edi/summary`\n* frontend panel: live plots of C(t), S_k(t), \u03a6(t), knobs, and scenario toggles",
      "success": true,
      "learning": [
        "Updated confidence to 0.790",
        "Decreased learning rate due to high success",
        "Updated coherence to 0.833"
      ],
      "timestamp": "2025-12-22T15:29:45.817791"
    }
  ],
  "rules": [],
  "last_updated": "2025-12-22T15:29:45.817794"
}